{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aerial Cactus Identification\n",
    "\n",
    "This is my attempt at the Kaggle competition entitled Aerial Cactus Identification. The description, taken from [Kaggle](https://www.kaggle.com/), reads as follows: \n",
    "\n",
    " \"To assess the impact of climate change on Earth's flora and fauna, it is vital to quantify how human activities such as logging, mining, and agriculture are impacting our protected natural areas. Researchers in Mexico have created the VIGIA project, which aims to build a system for autonomous surveillance of protected areas. A first step in such an effort is the ability to recognize the vegetation inside the protected areas. In this competition, you are tasked with creation of an algorithm that can identify a specific type of cactus in aerial imagery.\"\n",
    " \n",
    "This project features a bunch of 32x32 images, some containing a columnar cactus. The goal to be predict which do or do not have these cacti. I will attempt this by using a convolutional neural network.\n",
    "\n",
    "We will begin by loading the packages we will end up using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The images must first be loaded into a numpy array so that it can be used in training and evaluating our neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load the images from a folder into a dictionary\n",
    "# Keys will be the file names, the images will be an np.array\n",
    "def load_images(folderpath):\n",
    "    images = {}\n",
    "    # Go through file of images, noting their name and loading the images\n",
    "    for filename in os.listdir(folderpath):\n",
    "        image = Image.open(os.path.join(folderpath,filename))\n",
    "        images[filename] = [np.array(image)]\n",
    "    # Convert images dictionary into a DataFrame\n",
    "    images_arrays = pd.DataFrame.from_dict(images,orient='index').reset_index().rename({'index':'id'},axis=1)\n",
    "    return images_arrays\n",
    "# For the training data, we will also want to include the labels\n",
    "def load_training_images(labelfile, folderpath):\n",
    "    images_arrays = load_images(folderpath)\n",
    "    # Read labels of images into a DataFrame\n",
    "    images_labels = pd.read_csv(labelfile)\n",
    "    # Combine labels with the images into a DataFrame\n",
    "    images_df = images_arrays.merge(images_labels, left_on='id', right_on='id').drop(['id'],axis=1)\n",
    "    # Return DataFrame with labels and image arrays\n",
    "    return images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the define above function to load our images\n",
    "training_df = load_training_images('./train.csv', './train')\n",
    "pred_df = load_images('./test')\n",
    "\n",
    "# We can split the training dataframe into the image arrays and the labels\n",
    "X_full = np.stack(training_df.iloc[:,0].values.tolist())\n",
    "y_full = training_df.iloc[:,1].values.reshape((len(training_df.iloc[:,1]),1))\n",
    "\n",
    "# We will also want to split up the testing data into the just the image arrays\n",
    "X_pred_raw = np.stack(pred_df[0])\n",
    "\n",
    "# Decide on how much to split the training and test sets by\n",
    "test_size = 0.10\n",
    "# Split these into training and test sets\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_full, y_full, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 15750\n",
      "number of +ve training examples = 11821\n",
      "number of test examples = 1750\n",
      "number of +ve test examples = 1315\n",
      "X_train shape: (15750, 32, 32, 3)\n",
      "Y_train shape: (15750, 1)\n",
      "X_test shape: (1750, 32, 32, 3)\n",
      "Y_test shape: (1750, 1)\n",
      "X_pred shape: (4000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# We normalize the data and cast as correct type\n",
    "X_train = (X_train_raw/255.).astype(np.float32)\n",
    "X_test = (X_test_raw/255.).astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "X_pred = (X_pred_raw/255.).astype(np.float32)\n",
    "\n",
    "# Print out some details of the training/test sets\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of +ve training examples = \" + str(sum(y_train == 1)[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"number of +ve test examples = \" + str(sum(y_test == 1)[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(y_test.shape))\n",
    "print(\"X_pred shape: \" + str(X_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "Now we will go into defining the model. We will look at a convoluational neural network with two convoluational layers, with activations and max pooling layers in between. Then there is 2 fully connected layers before the final predictive layer. We begin by defining the hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Layer filer sizes\n",
    "cl1fs = 5\n",
    "cl2fs = 3\n",
    "# CNN Layer stride\n",
    "cl1s = 1\n",
    "cl2s = 1\n",
    "# CNN Layer output sizes\n",
    "cl1nc = 8\n",
    "cl2nc = 16\n",
    "# Max pooling layer window sizes\n",
    "ml1ws = 2\n",
    "ml2ws = 2\n",
    "# Max pooling layer strides\n",
    "ml1s = 2\n",
    "ml2s = 2\n",
    "# Fully connected layer sizes\n",
    "f1s = 512\n",
    "f2s = 256\n",
    "# Learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Extracted dimensions from above hyperparameters\n",
    "# Output dim after first max pool\n",
    "ml1dim = int((32 - ml1ws)/ml1s)+1\n",
    "# Output dim after second max pool\n",
    "ml2dim = int((ml1dim-ml2ws)/ml2s)+1\n",
    "# Output dim after flatten\n",
    "fladim = ml2dim*ml2dim*cl2nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC is the metric of the problem, so we want to use in during training\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using Keras layers\n",
    "def model_construction():\n",
    "    model = Sequential()\n",
    "    # Convolutional layer: channels cl1nc, stride cl1s, padding 'SAME'\n",
    "    model.add(Conv2D(filters = cl1nc, kernel_size = cl1fs, strides=cl1s, padding='same'))\n",
    "    # Max pooling: window ml1ws x ml1ws, stride ml1s, padding 'valid'\n",
    "    model.add(MaxPool2D(pool_size = ml1ws, strides = ml1s, padding = 'valid'))\n",
    "    # Convolutional layer: channels cl2nc, stride cl2s, padding 'SAME'\n",
    "    model.add(Conv2D(filters = cl2nc, kernel_size = cl2fs, strides=cl2s, padding='same'))\n",
    "    # Max pooling: window ml2ws x ml2ws, stride ml2s, padding 'valid'\n",
    "    model.add(MaxPool2D(pool_size = ml2ws, strides = ml2s, padding = 'valid'))\n",
    "    # Flatten tensor\n",
    "    model.add(Flatten())\n",
    "    # Fully connected layer: size f1s, activation RELU\n",
    "    model.add(Dense(units = f1s, activation = 'relu'))\n",
    "    # Fully connected layer size f2s, activation RELU\n",
    "    model.add(Dense(units = f2s, activation = 'relu'))\n",
    "    # Fully connected layer size 1 (predictive), activation sigmoid\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    # Compile the model with Adams optimizer, crossentropy loss and metric AUC\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[auc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 15750 samples, validate on 1750 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.4220 - auc: 0.6959 - val_loss: 0.2810 - val_auc: 0.8464\n",
      "Epoch 2/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.2062 - auc: 0.8888 - val_loss: 0.2103 - val_auc: 0.9158\n",
      "Epoch 3/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1608 - auc: 0.9297 - val_loss: 0.1466 - val_auc: 0.9411\n",
      "Epoch 4/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1353 - auc: 0.9486 - val_loss: 0.1276 - val_auc: 0.9547\n",
      "Epoch 5/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1264 - auc: 0.9591 - val_loss: 0.1108 - val_auc: 0.9628\n",
      "Epoch 6/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1236 - auc: 0.9657 - val_loss: 0.1393 - val_auc: 0.9678\n",
      "Epoch 7/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1094 - auc: 0.9697 - val_loss: 0.1021 - val_auc: 0.9717\n",
      "Epoch 8/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1353 - auc: 0.9728 - val_loss: 0.1288 - val_auc: 0.9735\n",
      "Epoch 9/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1254 - auc: 0.9744 - val_loss: 0.1040 - val_auc: 0.9752\n",
      "Epoch 10/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1002 - auc: 0.9762 - val_loss: 0.1018 - val_auc: 0.9773\n",
      "Epoch 11/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0910 - auc: 0.9781 - val_loss: 0.1002 - val_auc: 0.9790\n",
      "Epoch 12/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0877 - auc: 0.9798 - val_loss: 0.0981 - val_auc: 0.9805\n",
      "Epoch 13/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0818 - auc: 0.9812 - val_loss: 0.0842 - val_auc: 0.9818\n",
      "Epoch 14/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0795 - auc: 0.9824 - val_loss: 0.0822 - val_auc: 0.9830\n",
      "Epoch 15/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0772 - auc: 0.9835 - val_loss: 0.0941 - val_auc: 0.9840\n",
      "Epoch 16/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0777 - auc: 0.9844 - val_loss: 0.0807 - val_auc: 0.9848\n",
      "Epoch 17/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0703 - auc: 0.9852 - val_loss: 0.0697 - val_auc: 0.9856\n",
      "Epoch 18/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0655 - auc: 0.9860 - val_loss: 0.0695 - val_auc: 0.9864\n",
      "Epoch 19/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0612 - auc: 0.9868 - val_loss: 0.0880 - val_auc: 0.9871\n",
      "Epoch 20/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0608 - auc: 0.9874 - val_loss: 0.0762 - val_auc: 0.9877\n",
      "Epoch 21/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0742 - auc: 0.9879 - val_loss: 0.0723 - val_auc: 0.9881\n",
      "Epoch 22/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0542 - auc: 0.9884 - val_loss: 0.1324 - val_auc: 0.9886\n",
      "Epoch 23/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0540 - auc: 0.9888 - val_loss: 0.0649 - val_auc: 0.9891\n",
      "Epoch 24/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0447 - auc: 0.9894 - val_loss: 0.0667 - val_auc: 0.9896\n",
      "Epoch 25/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0412 - auc: 0.9899 - val_loss: 0.0688 - val_auc: 0.9901\n",
      "Epoch 26/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0387 - auc: 0.9903 - val_loss: 0.0568 - val_auc: 0.9905\n",
      "Epoch 27/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0343 - auc: 0.9908 - val_loss: 0.0695 - val_auc: 0.9910\n",
      "Epoch 28/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0324 - auc: 0.9912 - val_loss: 0.0588 - val_auc: 0.9914\n",
      "Epoch 29/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0404 - auc: 0.9916 - val_loss: 0.1190 - val_auc: 0.9917\n",
      "Epoch 30/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0405 - auc: 0.9918 - val_loss: 0.0679 - val_auc: 0.9920\n",
      "Epoch 31/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0224 - auc: 0.9921 - val_loss: 0.0589 - val_auc: 0.9923\n",
      "Epoch 32/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0236 - auc: 0.9925 - val_loss: 0.0984 - val_auc: 0.9926\n",
      "Epoch 33/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0189 - auc: 0.9928 - val_loss: 0.0632 - val_auc: 0.9929\n",
      "Epoch 34/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0105 - auc: 0.9931 - val_loss: 0.0582 - val_auc: 0.9933\n",
      "Epoch 35/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0077 - auc: 0.9934 - val_loss: 0.0647 - val_auc: 0.9936\n",
      "Epoch 36/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0068 - auc: 0.9937 - val_loss: 0.0627 - val_auc: 0.9939\n",
      "Epoch 37/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1008 - auc: 0.9940 - val_loss: 0.7598 - val_auc: 0.9935\n",
      "Epoch 38/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.1579 - auc: 0.9931 - val_loss: 0.0756 - val_auc: 0.9931\n",
      "Epoch 39/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0327 - auc: 0.9932 - val_loss: 0.0593 - val_auc: 0.9933\n",
      "Epoch 40/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0232 - auc: 0.9934 - val_loss: 0.0886 - val_auc: 0.9935\n",
      "Epoch 41/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0133 - auc: 0.9936 - val_loss: 0.0797 - val_auc: 0.9937\n",
      "Epoch 42/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0089 - auc: 0.9938 - val_loss: 0.0629 - val_auc: 0.9939\n",
      "Epoch 43/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0062 - auc: 0.9941 - val_loss: 0.0655 - val_auc: 0.9942\n",
      "Epoch 44/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0046 - auc: 0.9943 - val_loss: 0.0650 - val_auc: 0.9944\n",
      "Epoch 45/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0037 - auc: 0.9945 - val_loss: 0.0660 - val_auc: 0.9946\n",
      "Epoch 46/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0028 - auc: 0.9947 - val_loss: 0.0701 - val_auc: 0.9948\n",
      "Epoch 47/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0025 - auc: 0.9948 - val_loss: 0.0741 - val_auc: 0.9949\n",
      "Epoch 48/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0023 - auc: 0.9950 - val_loss: 0.0704 - val_auc: 0.9951\n",
      "Epoch 49/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0021 - auc: 0.9952 - val_loss: 0.0727 - val_auc: 0.9952\n",
      "Epoch 50/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0016 - auc: 0.9953 - val_loss: 0.0730 - val_auc: 0.9954\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 0.0012 - auc: 0.9955 - val_loss: 0.0703 - val_auc: 0.9955\n",
      "Epoch 52/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 8.3330e-04 - auc: 0.9956 - val_loss: 0.0746 - val_auc: 0.9957\n",
      "Epoch 53/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 6.6889e-04 - auc: 0.9957 - val_loss: 0.0724 - val_auc: 0.9958\n",
      "Epoch 54/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.3666e-04 - auc: 0.9959 - val_loss: 0.0751 - val_auc: 0.9959\n",
      "Epoch 55/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.6344e-04 - auc: 0.9960 - val_loss: 0.0765 - val_auc: 0.9960\n",
      "Epoch 56/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.2259e-04 - auc: 0.9961 - val_loss: 0.0773 - val_auc: 0.9961\n",
      "Epoch 57/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.2602e-04 - auc: 0.9962 - val_loss: 0.0819 - val_auc: 0.9962\n",
      "Epoch 58/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.3488e-04 - auc: 0.9963 - val_loss: 0.0792 - val_auc: 0.9963\n",
      "Epoch 59/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.2452e-04 - auc: 0.9964 - val_loss: 0.0765 - val_auc: 0.9964\n",
      "Epoch 60/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.7188e-04 - auc: 0.9965 - val_loss: 0.0797 - val_auc: 0.9965\n",
      "Epoch 61/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.5346e-04 - auc: 0.9965 - val_loss: 0.0798 - val_auc: 0.9966\n",
      "Epoch 62/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.2369e-04 - auc: 0.9966 - val_loss: 0.0789 - val_auc: 0.9967\n",
      "Epoch 63/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.0348e-04 - auc: 0.9967 - val_loss: 0.0802 - val_auc: 0.9967\n",
      "Epoch 64/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.8505e-04 - auc: 0.9968 - val_loss: 0.0808 - val_auc: 0.9968\n",
      "Epoch 65/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.6468e-04 - auc: 0.9968 - val_loss: 0.0822 - val_auc: 0.9969\n",
      "Epoch 66/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.5272e-04 - auc: 0.9969 - val_loss: 0.0828 - val_auc: 0.9969\n",
      "Epoch 67/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.4100e-04 - auc: 0.9970 - val_loss: 0.0831 - val_auc: 0.9970\n",
      "Epoch 68/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.3207e-04 - auc: 0.9970 - val_loss: 0.0829 - val_auc: 0.9971\n",
      "Epoch 69/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.2437e-04 - auc: 0.9971 - val_loss: 0.0829 - val_auc: 0.9971\n",
      "Epoch 70/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.1196e-04 - auc: 0.9971 - val_loss: 0.0833 - val_auc: 0.9972\n",
      "Epoch 71/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.0558e-04 - auc: 0.9972 - val_loss: 0.0844 - val_auc: 0.9972\n",
      "Epoch 72/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.0949e-04 - auc: 0.9973 - val_loss: 0.0849 - val_auc: 0.9973\n",
      "Epoch 73/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 9.1779e-05 - auc: 0.9973 - val_loss: 0.0852 - val_auc: 0.9973\n",
      "Epoch 74/200\n",
      "15750/15750 [==============================] - 18s 1ms/sample - loss: 8.4485e-05 - auc: 0.9974 - val_loss: 0.0854 - val_auc: 0.9974\n",
      "Epoch 75/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 7.9426e-05 - auc: 0.9974 - val_loss: 0.0861 - val_auc: 0.9974\n",
      "Epoch 76/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 7.3453e-05 - auc: 0.9974 - val_loss: 0.0852 - val_auc: 0.9975\n",
      "Epoch 77/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 7.0119e-05 - auc: 0.9975 - val_loss: 0.0879 - val_auc: 0.9975\n",
      "Epoch 78/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 6.5737e-05 - auc: 0.9975 - val_loss: 0.0871 - val_auc: 0.9975\n",
      "Epoch 79/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 6.0822e-05 - auc: 0.9976 - val_loss: 0.0857 - val_auc: 0.9976\n",
      "Epoch 80/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.8130e-05 - auc: 0.9976 - val_loss: 0.0875 - val_auc: 0.9976\n",
      "Epoch 81/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.3910e-05 - auc: 0.9976 - val_loss: 0.0875 - val_auc: 0.9976\n",
      "Epoch 82/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.0324e-05 - auc: 0.9977 - val_loss: 0.0878 - val_auc: 0.9977\n",
      "Epoch 83/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.9423e-05 - auc: 0.9977 - val_loss: 0.0882 - val_auc: 0.9977\n",
      "Epoch 84/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.6801e-05 - auc: 0.9977 - val_loss: 0.0876 - val_auc: 0.9977\n",
      "Epoch 85/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.3719e-05 - auc: 0.9978 - val_loss: 0.0881 - val_auc: 0.9978\n",
      "Epoch 86/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.0717e-05 - auc: 0.9978 - val_loss: 0.0886 - val_auc: 0.9978\n",
      "Epoch 87/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.9216e-05 - auc: 0.9978 - val_loss: 0.0885 - val_auc: 0.9978\n",
      "Epoch 88/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.6810e-05 - auc: 0.9979 - val_loss: 0.0890 - val_auc: 0.9979\n",
      "Epoch 89/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.4930e-05 - auc: 0.9979 - val_loss: 0.0900 - val_auc: 0.9979\n",
      "Epoch 90/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.3215e-05 - auc: 0.9979 - val_loss: 0.0897 - val_auc: 0.9979\n",
      "Epoch 91/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.1607e-05 - auc: 0.9979 - val_loss: 0.0897 - val_auc: 0.9979\n",
      "Epoch 92/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.0202e-05 - auc: 0.9980 - val_loss: 0.0909 - val_auc: 0.9980\n",
      "Epoch 93/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.9311e-05 - auc: 0.9980 - val_loss: 0.0905 - val_auc: 0.9980\n",
      "Epoch 94/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.7125e-05 - auc: 0.9980 - val_loss: 0.0909 - val_auc: 0.9980\n",
      "Epoch 95/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.6063e-05 - auc: 0.9980 - val_loss: 0.0906 - val_auc: 0.9980\n",
      "Epoch 96/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.4809e-05 - auc: 0.9980 - val_loss: 0.0914 - val_auc: 0.9981\n",
      "Epoch 97/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.3499e-05 - auc: 0.9981 - val_loss: 0.0919 - val_auc: 0.9981\n",
      "Epoch 98/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.2611e-05 - auc: 0.9981 - val_loss: 0.0917 - val_auc: 0.9981\n",
      "Epoch 99/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.1728e-05 - auc: 0.9981 - val_loss: 0.0924 - val_auc: 0.9981\n",
      "Epoch 100/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.0681e-05 - auc: 0.9981 - val_loss: 0.0924 - val_auc: 0.9981\n",
      "Epoch 101/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.0669e-05 - auc: 0.9981 - val_loss: 0.0922 - val_auc: 0.9982\n",
      "Epoch 102/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.9579e-05 - auc: 0.9982 - val_loss: 0.0929 - val_auc: 0.9982\n",
      "Epoch 103/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.8209e-05 - auc: 0.9982 - val_loss: 0.0927 - val_auc: 0.9982\n",
      "Epoch 104/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.7439e-05 - auc: 0.9982 - val_loss: 0.0936 - val_auc: 0.9982\n",
      "Epoch 105/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.6827e-05 - auc: 0.9982 - val_loss: 0.0935 - val_auc: 0.9982\n",
      "Epoch 106/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.6361e-05 - auc: 0.9982 - val_loss: 0.0934 - val_auc: 0.9982\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.5453e-05 - auc: 0.9982 - val_loss: 0.0940 - val_auc: 0.9982\n",
      "Epoch 108/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.4798e-05 - auc: 0.9983 - val_loss: 0.0945 - val_auc: 0.9983\n",
      "Epoch 109/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.4161e-05 - auc: 0.9983 - val_loss: 0.0942 - val_auc: 0.9983\n",
      "Epoch 110/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.3634e-05 - auc: 0.9983 - val_loss: 0.0940 - val_auc: 0.9983\n",
      "Epoch 111/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.3100e-05 - auc: 0.9983 - val_loss: 0.0948 - val_auc: 0.9983\n",
      "Epoch 112/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.2650e-05 - auc: 0.9983 - val_loss: 0.0944 - val_auc: 0.9983\n",
      "Epoch 113/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.2347e-05 - auc: 0.9983 - val_loss: 0.0948 - val_auc: 0.9983\n",
      "Epoch 114/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.1934e-05 - auc: 0.9983 - val_loss: 0.0958 - val_auc: 0.9983\n",
      "Epoch 115/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.1309e-05 - auc: 0.9984 - val_loss: 0.0962 - val_auc: 0.9984\n",
      "Epoch 116/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.1037e-05 - auc: 0.9984 - val_loss: 0.0957 - val_auc: 0.9984\n",
      "Epoch 117/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.0979e-05 - auc: 0.9984 - val_loss: 0.0961 - val_auc: 0.9984\n",
      "Epoch 118/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.0597e-05 - auc: 0.9984 - val_loss: 0.0960 - val_auc: 0.9984\n",
      "Epoch 119/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 9.9572e-06 - auc: 0.9984 - val_loss: 0.0966 - val_auc: 0.9984\n",
      "Epoch 120/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 9.6409e-06 - auc: 0.9984 - val_loss: 0.0965 - val_auc: 0.9984\n",
      "Epoch 121/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 9.1911e-06 - auc: 0.9984 - val_loss: 0.0964 - val_auc: 0.9984\n",
      "Epoch 122/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 8.8558e-06 - auc: 0.9984 - val_loss: 0.0971 - val_auc: 0.9984\n",
      "Epoch 123/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 8.6023e-06 - auc: 0.9984 - val_loss: 0.0976 - val_auc: 0.9984\n",
      "Epoch 124/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 8.3780e-06 - auc: 0.9984 - val_loss: 0.0968 - val_auc: 0.9985\n",
      "Epoch 125/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 8.0542e-06 - auc: 0.9985 - val_loss: 0.0977 - val_auc: 0.9985\n",
      "Epoch 126/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 7.8759e-06 - auc: 0.9985 - val_loss: 0.0973 - val_auc: 0.9985\n",
      "Epoch 127/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 7.5951e-06 - auc: 0.9985 - val_loss: 0.0977 - val_auc: 0.9985\n",
      "Epoch 128/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 7.3626e-06 - auc: 0.9985 - val_loss: 0.0990 - val_auc: 0.9985\n",
      "Epoch 129/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 7.1506e-06 - auc: 0.9985 - val_loss: 0.0983 - val_auc: 0.9985\n",
      "Epoch 130/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 6.9792e-06 - auc: 0.9985 - val_loss: 0.0980 - val_auc: 0.9985\n",
      "Epoch 131/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 6.7664e-06 - auc: 0.9985 - val_loss: 0.0990 - val_auc: 0.9985\n",
      "Epoch 132/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 6.6167e-06 - auc: 0.9985 - val_loss: 0.0987 - val_auc: 0.9985\n",
      "Epoch 133/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 6.3854e-06 - auc: 0.9985 - val_loss: 0.0984 - val_auc: 0.9985\n",
      "Epoch 134/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 6.1685e-06 - auc: 0.9985 - val_loss: 0.0990 - val_auc: 0.9985\n",
      "Epoch 135/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.9656e-06 - auc: 0.9985 - val_loss: 0.0991 - val_auc: 0.9985\n",
      "Epoch 136/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.8510e-06 - auc: 0.9985 - val_loss: 0.0995 - val_auc: 0.9985\n",
      "Epoch 137/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.6670e-06 - auc: 0.9986 - val_loss: 0.0999 - val_auc: 0.9986\n",
      "Epoch 138/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.5354e-06 - auc: 0.9986 - val_loss: 0.0994 - val_auc: 0.9986\n",
      "Epoch 139/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.3394e-06 - auc: 0.9986 - val_loss: 0.0995 - val_auc: 0.9986\n",
      "Epoch 140/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.1845e-06 - auc: 0.9986 - val_loss: 0.1002 - val_auc: 0.9986\n",
      "Epoch 141/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 5.0888e-06 - auc: 0.9986 - val_loss: 0.1004 - val_auc: 0.9986\n",
      "Epoch 142/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.9896e-06 - auc: 0.9986 - val_loss: 0.1002 - val_auc: 0.9986\n",
      "Epoch 143/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.8040e-06 - auc: 0.9986 - val_loss: 0.1005 - val_auc: 0.9986\n",
      "Epoch 144/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.6810e-06 - auc: 0.9986 - val_loss: 0.1009 - val_auc: 0.9986\n",
      "Epoch 145/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.5742e-06 - auc: 0.9986 - val_loss: 0.1010 - val_auc: 0.9986\n",
      "Epoch 146/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.4719e-06 - auc: 0.9986 - val_loss: 0.1004 - val_auc: 0.9986\n",
      "Epoch 147/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.3338e-06 - auc: 0.9986 - val_loss: 0.1010 - val_auc: 0.9986\n",
      "Epoch 148/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.2540e-06 - auc: 0.9986 - val_loss: 0.1016 - val_auc: 0.9986\n",
      "Epoch 149/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.1345e-06 - auc: 0.9986 - val_loss: 0.1004 - val_auc: 0.9986\n",
      "Epoch 150/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 4.0185e-06 - auc: 0.9986 - val_loss: 0.1012 - val_auc: 0.9986\n",
      "Epoch 151/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.9368e-06 - auc: 0.9986 - val_loss: 0.1009 - val_auc: 0.9986\n",
      "Epoch 152/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.8221e-06 - auc: 0.9986 - val_loss: 0.1023 - val_auc: 0.9986\n",
      "Epoch 153/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.7245e-06 - auc: 0.9986 - val_loss: 0.1020 - val_auc: 0.9986\n",
      "Epoch 154/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.6966e-06 - auc: 0.9986 - val_loss: 0.1023 - val_auc: 0.9986\n",
      "Epoch 155/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.5434e-06 - auc: 0.9987 - val_loss: 0.1023 - val_auc: 0.9987\n",
      "Epoch 156/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.4729e-06 - auc: 0.9987 - val_loss: 0.1021 - val_auc: 0.9987\n",
      "Epoch 157/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.4362e-06 - auc: 0.9987 - val_loss: 0.1022 - val_auc: 0.9987\n",
      "Epoch 158/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.3554e-06 - auc: 0.9987 - val_loss: 0.1029 - val_auc: 0.9987\n",
      "Epoch 159/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.2239e-06 - auc: 0.9987 - val_loss: 0.1030 - val_auc: 0.9987\n",
      "Epoch 160/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.1903e-06 - auc: 0.9987 - val_loss: 0.1031 - val_auc: 0.9987\n",
      "Epoch 161/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.0884e-06 - auc: 0.9987 - val_loss: 0.1033 - val_auc: 0.9987\n",
      "Epoch 162/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 3.0159e-06 - auc: 0.9987 - val_loss: 0.1041 - val_auc: 0.9987\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.9321e-06 - auc: 0.9987 - val_loss: 0.1027 - val_auc: 0.9987\n",
      "Epoch 164/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.8891e-06 - auc: 0.9987 - val_loss: 0.1029 - val_auc: 0.9987\n",
      "Epoch 165/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.8194e-06 - auc: 0.9987 - val_loss: 0.1033 - val_auc: 0.9987\n",
      "Epoch 166/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.7545e-06 - auc: 0.9987 - val_loss: 0.1040 - val_auc: 0.9987\n",
      "Epoch 167/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.6589e-06 - auc: 0.9987 - val_loss: 0.1035 - val_auc: 0.9987\n",
      "Epoch 168/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.6250e-06 - auc: 0.9987 - val_loss: 0.1053 - val_auc: 0.9987\n",
      "Epoch 169/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.5580e-06 - auc: 0.9987 - val_loss: 0.1040 - val_auc: 0.9987\n",
      "Epoch 170/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.4951e-06 - auc: 0.9987 - val_loss: 0.1047 - val_auc: 0.9987\n",
      "Epoch 171/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.4372e-06 - auc: 0.9987 - val_loss: 0.1053 - val_auc: 0.9987\n",
      "Epoch 172/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.4014e-06 - auc: 0.9987 - val_loss: 0.1043 - val_auc: 0.9987\n",
      "Epoch 173/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.3330e-06 - auc: 0.9987 - val_loss: 0.1042 - val_auc: 0.9987\n",
      "Epoch 174/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.2940e-06 - auc: 0.9987 - val_loss: 0.1051 - val_auc: 0.9987\n",
      "Epoch 175/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.2410e-06 - auc: 0.9987 - val_loss: 0.1050 - val_auc: 0.9987\n",
      "Epoch 176/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.1858e-06 - auc: 0.9987 - val_loss: 0.1051 - val_auc: 0.9987\n",
      "Epoch 177/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.1416e-06 - auc: 0.9987 - val_loss: 0.1045 - val_auc: 0.9987\n",
      "Epoch 178/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.0949e-06 - auc: 0.9987 - val_loss: 0.1061 - val_auc: 0.9987\n",
      "Epoch 179/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.0702e-06 - auc: 0.9987 - val_loss: 0.1057 - val_auc: 0.9987\n",
      "Epoch 180/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 2.0290e-06 - auc: 0.9987 - val_loss: 0.1055 - val_auc: 0.9987\n",
      "Epoch 181/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.9674e-06 - auc: 0.9987 - val_loss: 0.1056 - val_auc: 0.9987\n",
      "Epoch 182/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.9572e-06 - auc: 0.9987 - val_loss: 0.1053 - val_auc: 0.9987\n",
      "Epoch 183/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.8863e-06 - auc: 0.9987 - val_loss: 0.1061 - val_auc: 0.9987\n",
      "Epoch 184/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.8489e-06 - auc: 0.9987 - val_loss: 0.1062 - val_auc: 0.9987\n",
      "Epoch 185/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.8191e-06 - auc: 0.9987 - val_loss: 0.1058 - val_auc: 0.9987\n",
      "Epoch 186/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.7699e-06 - auc: 0.9987 - val_loss: 0.1060 - val_auc: 0.9987\n",
      "Epoch 187/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.7377e-06 - auc: 0.9987 - val_loss: 0.1061 - val_auc: 0.9987\n",
      "Epoch 188/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.7003e-06 - auc: 0.9987 - val_loss: 0.1067 - val_auc: 0.9987\n",
      "Epoch 189/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.6753e-06 - auc: 0.9988 - val_loss: 0.1061 - val_auc: 0.9988\n",
      "Epoch 190/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.6266e-06 - auc: 0.9988 - val_loss: 0.1069 - val_auc: 0.9988\n",
      "Epoch 191/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.6053e-06 - auc: 0.9988 - val_loss: 0.1066 - val_auc: 0.9988\n",
      "Epoch 192/200\n",
      "15750/15750 [==============================] - 18s 1ms/sample - loss: 1.5772e-06 - auc: 0.9988 - val_loss: 0.1066 - val_auc: 0.9988\n",
      "Epoch 193/200\n",
      "15750/15750 [==============================] - 20s 1ms/sample - loss: 1.5476e-06 - auc: 0.9988 - val_loss: 0.1070 - val_auc: 0.9988\n",
      "Epoch 194/200\n",
      "15750/15750 [==============================] - 18s 1ms/sample - loss: 1.5151e-06 - auc: 0.9988 - val_loss: 0.1070 - val_auc: 0.9988\n",
      "Epoch 195/200\n",
      "15750/15750 [==============================] - 18s 1ms/sample - loss: 1.4797e-06 - auc: 0.9988 - val_loss: 0.1069 - val_auc: 0.9988\n",
      "Epoch 196/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.4477e-06 - auc: 0.9988 - val_loss: 0.1078 - val_auc: 0.9988\n",
      "Epoch 197/200\n",
      "15750/15750 [==============================] - 19s 1ms/sample - loss: 1.4374e-06 - auc: 0.9988 - val_loss: 0.1075 - val_auc: 0.9988\n",
      "Epoch 198/200\n",
      "15750/15750 [==============================] - 17s 1ms/sample - loss: 1.4058e-06 - auc: 0.9988 - val_loss: 0.1076 - val_auc: 0.9988\n",
      "Epoch 199/200\n",
      "15750/15750 [==============================] - 19s 1ms/sample - loss: 1.3650e-06 - auc: 0.9988 - val_loss: 0.1073 - val_auc: 0.9988\n",
      "Epoch 200/200\n",
      "15750/15750 [==============================] - 19s 1ms/sample - loss: 1.3425e-06 - auc: 0.9988 - val_loss: 0.1078 - val_auc: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x160c24eec50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we train the constructed network to with our training data\n",
    "model = model_construction()\n",
    "model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=200, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = model.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000940378805c44108d287872b2f04ce.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0017242f54ececa4512b4d7937d1e21e.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ee6d8564003107853118ab87df407.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002e175c3c1e060769475f52182583d0.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0036e44a7e8f7218e9bc7bf8137e4943.jpg</td>\n",
       "      <td>6.207111e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0038ed6f7417b8275b393307f66cb1e3.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0059dfa41de4441fc23b9a4b98ba99cb.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0061bd302d735db829418cb90b4e6040.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00754573d8c7223e73da553dd43780bd.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008d9fce71c8e03a4c9cdd15ea908573.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00a36d4d6d152404670276fc983273bc.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00b706122b87e0fa275ff59e39d4d94b.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00c054da839d5518e59790f7d867f317.jpg</td>\n",
       "      <td>9.995524e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00c88441b0510cdb3a6e9b3fa7b632af.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00e1e29865202c8ca715b0f14848d577.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00e20b0e6d779e7c36cea29710eed88e.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00feb0be23ac80f397a55b0ed8502def.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01185a1a81bb8041fa5e9c9ada9374eb.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0124398c0fcf6d1c92d9800337636b4e.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0127044dfc88dfaed0118c8764909800.jpg</td>\n",
       "      <td>8.846521e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>012c260033e652ab9690ea4bb3f63483.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0145b0da83f36fcfe1a1309355154c9f.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>01723d584648a9c88704625121443d46.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>017396273d436137bbecaeb650dca415.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0188f5ba08afcb5fa036a8c48aff1d1a.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>01a840130560403d291c6b7cb3ed6cf3.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>01b73e88077f801b357064e7dd914db6.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>01c77430f6e5062bfde2427cdd312a39.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>01cd51bb115fe5c0c37acd8d8800613e.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>01e890418e216253bf5339ee4c96b65e.jpg</td>\n",
       "      <td>9.999965e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>fe3af39f7ed104cb1a1d3764b0df3d8b.jpg</td>\n",
       "      <td>9.745359e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>fe595c2f96952db75f8dea9e6d2a6402.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>fe6f5c37f1bd08202390b617d5405a48.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>fe75980d25479a3410a97a0a612f2bd6.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>fe875b77445bae122678aa8ad855ff77.jpg</td>\n",
       "      <td>9.999945e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>fe8d3adf09859c03d6d7baf9dc1042f8.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>fe958d4dfeba58fa21cacc156246a320.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>feb5e97217dde30ad23505a9bc246c12.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>febf18e1e32539bd2014e83376e297ed.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>fef042cf395d8d236c7a222ca6111f6f.jpg</td>\n",
       "      <td>6.778365e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>fef24110b83b6fc439f6fa823ad6ce78.jpg</td>\n",
       "      <td>9.999872e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>ff01372293362bd068923395535d831f.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>ff0437b4c375e4e8cd8ebba5ecab3500.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>ff0cba3dc2ea18ce5cff5a2379f1d927.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>ff1c471a319b31a8b570df85e344a5d1.jpg</td>\n",
       "      <td>9.999986e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>ff2ebd7673bd012b5f5920039530479b.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>ff360b32a4cb50adf2f89ab3cfc9b6aa.jpg</td>\n",
       "      <td>1.192093e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>ff4d7f31dd2413ed8eef344470f20d97.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>ff680e4f9bb7283eaf4cbc7530099657.jpg</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>ff6d1ceccb9e19e750fc7e2c637c3c83.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>ff6f8ae36c1d66214127fe5008789407.jpg</td>\n",
       "      <td>9.029868e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>ff7403812efdc9ec93301c32e8f39c30.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>ff8bc1e0fe61fba8ea9a05c91cd0933a.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>ff9937f41664d329822e72c6a14d3f16.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>ff9c0bafab5f89febd18c1d6865c079b.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>ffaafd0c9f2f0e73172848463bc2e523.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>ffae37344310a1549162493237d25d3f.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>ffbd469c56873d064326204aac546e0d.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>ffcb76b7d47f29ece11c751e5f763f52.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>fffed17d1a8e0433a934db518d7f532c.jpg</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id    has_cactus\n",
       "0     000940378805c44108d287872b2f04ce.jpg  1.000000e+00\n",
       "1     0017242f54ececa4512b4d7937d1e21e.jpg  1.000000e+00\n",
       "2     001ee6d8564003107853118ab87df407.jpg  0.000000e+00\n",
       "3     002e175c3c1e060769475f52182583d0.jpg  0.000000e+00\n",
       "4     0036e44a7e8f7218e9bc7bf8137e4943.jpg  6.207111e-02\n",
       "5     0038ed6f7417b8275b393307f66cb1e3.jpg  1.000000e+00\n",
       "6     0059dfa41de4441fc23b9a4b98ba99cb.jpg  1.000000e+00\n",
       "7     0061bd302d735db829418cb90b4e6040.jpg  1.000000e+00\n",
       "8     00754573d8c7223e73da553dd43780bd.jpg  1.000000e+00\n",
       "9     008d9fce71c8e03a4c9cdd15ea908573.jpg  0.000000e+00\n",
       "10    00a36d4d6d152404670276fc983273bc.jpg  1.000000e+00\n",
       "11    00b706122b87e0fa275ff59e39d4d94b.jpg  1.000000e+00\n",
       "12    00c054da839d5518e59790f7d867f317.jpg  9.995524e-01\n",
       "13    00c88441b0510cdb3a6e9b3fa7b632af.jpg  1.000000e+00\n",
       "14    00e1e29865202c8ca715b0f14848d577.jpg  0.000000e+00\n",
       "15    00e20b0e6d779e7c36cea29710eed88e.jpg  1.000000e+00\n",
       "16    00feb0be23ac80f397a55b0ed8502def.jpg  1.000000e+00\n",
       "17    01185a1a81bb8041fa5e9c9ada9374eb.jpg  1.000000e+00\n",
       "18    0124398c0fcf6d1c92d9800337636b4e.jpg  1.000000e+00\n",
       "19    0127044dfc88dfaed0118c8764909800.jpg  8.846521e-04\n",
       "20    012c260033e652ab9690ea4bb3f63483.jpg  1.000000e+00\n",
       "21    0145b0da83f36fcfe1a1309355154c9f.jpg  0.000000e+00\n",
       "22    01723d584648a9c88704625121443d46.jpg  1.000000e+00\n",
       "23    017396273d436137bbecaeb650dca415.jpg  0.000000e+00\n",
       "24    0188f5ba08afcb5fa036a8c48aff1d1a.jpg  1.000000e+00\n",
       "25    01a840130560403d291c6b7cb3ed6cf3.jpg  0.000000e+00\n",
       "26    01b73e88077f801b357064e7dd914db6.jpg  1.000000e+00\n",
       "27    01c77430f6e5062bfde2427cdd312a39.jpg  1.000000e+00\n",
       "28    01cd51bb115fe5c0c37acd8d8800613e.jpg  1.000000e+00\n",
       "29    01e890418e216253bf5339ee4c96b65e.jpg  9.999965e-01\n",
       "...                                    ...           ...\n",
       "3970  fe3af39f7ed104cb1a1d3764b0df3d8b.jpg  9.745359e-06\n",
       "3971  fe595c2f96952db75f8dea9e6d2a6402.jpg  1.000000e+00\n",
       "3972  fe6f5c37f1bd08202390b617d5405a48.jpg  0.000000e+00\n",
       "3973  fe75980d25479a3410a97a0a612f2bd6.jpg  1.000000e+00\n",
       "3974  fe875b77445bae122678aa8ad855ff77.jpg  9.999945e-01\n",
       "3975  fe8d3adf09859c03d6d7baf9dc1042f8.jpg  1.000000e+00\n",
       "3976  fe958d4dfeba58fa21cacc156246a320.jpg  0.000000e+00\n",
       "3977  feb5e97217dde30ad23505a9bc246c12.jpg  1.000000e+00\n",
       "3978  febf18e1e32539bd2014e83376e297ed.jpg  1.000000e+00\n",
       "3979  fef042cf395d8d236c7a222ca6111f6f.jpg  6.778365e-02\n",
       "3980  fef24110b83b6fc439f6fa823ad6ce78.jpg  9.999872e-01\n",
       "3981  ff01372293362bd068923395535d831f.jpg  1.000000e+00\n",
       "3982  ff0437b4c375e4e8cd8ebba5ecab3500.jpg  1.000000e+00\n",
       "3983  ff0cba3dc2ea18ce5cff5a2379f1d927.jpg  1.000000e+00\n",
       "3984  ff1c471a319b31a8b570df85e344a5d1.jpg  9.999986e-01\n",
       "3985  ff2ebd7673bd012b5f5920039530479b.jpg  1.000000e+00\n",
       "3986  ff360b32a4cb50adf2f89ab3cfc9b6aa.jpg  1.192093e-07\n",
       "3987  ff4d7f31dd2413ed8eef344470f20d97.jpg  0.000000e+00\n",
       "3988  ff680e4f9bb7283eaf4cbc7530099657.jpg  0.000000e+00\n",
       "3989  ff6d1ceccb9e19e750fc7e2c637c3c83.jpg  1.000000e+00\n",
       "3990  ff6f8ae36c1d66214127fe5008789407.jpg  9.029868e-01\n",
       "3991  ff7403812efdc9ec93301c32e8f39c30.jpg  1.000000e+00\n",
       "3992  ff8bc1e0fe61fba8ea9a05c91cd0933a.jpg  1.000000e+00\n",
       "3993  ff9937f41664d329822e72c6a14d3f16.jpg  1.000000e+00\n",
       "3994  ff9c0bafab5f89febd18c1d6865c079b.jpg  1.000000e+00\n",
       "3995  ffaafd0c9f2f0e73172848463bc2e523.jpg  1.000000e+00\n",
       "3996  ffae37344310a1549162493237d25d3f.jpg  1.000000e+00\n",
       "3997  ffbd469c56873d064326204aac546e0d.jpg  1.000000e+00\n",
       "3998  ffcb76b7d47f29ece11c751e5f763f52.jpg  1.000000e+00\n",
       "3999  fffed17d1a8e0433a934db518d7f532c.jpg  1.000000e+00\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can then prepare the predictions for submission\n",
    "submission = (pd.concat([pred_df['id'],pd.DataFrame(final_predictions)],axis=1)\n",
    "              .rename({0:'has_cactus'},axis=1)\n",
    "             )\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
